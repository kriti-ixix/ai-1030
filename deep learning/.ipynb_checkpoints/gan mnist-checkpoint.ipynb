{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad21e78a-3701-4f28-9e04-44e730493454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4eca3da-e736-496a-a160-535633aa6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad343164-13ee-448b-a680-9f11786b1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec34e63-9696-4922-bf3a-415bbbc6de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_zeroes = X_train[y_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18da73f-8890-49ae-997f-9ed1f426b7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5923, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_zeroes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f25ff55-a2da-4f5b-a93b-44bbf312f6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdd10098e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(only_zeroes[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8517cb08-606b-48e2-ac9c-65669105ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360d2202-5bab-4afc-9eda-4ed2085d560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "codings_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e699952-3073-4dc1-8aad-f8022987e7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ae0790-3085-4656-9f8c-d2a1189010f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 16:43:12.325411: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(100, activation='relu', input_shape=[codings_size]))\n",
    "generator.add(Dense(150, activation='relu'))\n",
    "generator.add(Dense(784, activation='sigmoid')) # 28 * 28 = 784\n",
    "generator.add(Reshape([28, 28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "974c2381-70fa-485f-a38c-a7db35e74688",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Flatten(input_shape=[28, 28]))\n",
    "discriminator.add(Dense(150, activation='relu'))\n",
    "discriminator.add(Dense(100, activation='relu'))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409038ac-872c-44a5-a7b5-5cefbb0079a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644eac06-ab4b-41b1-85e7-02e6812743b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23591292-2634-485e-bcb4-b960f0cf6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fbec63-a9b4-4b5d-b337-d492ecb0ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x7fdd101b46a0>,\n",
       " <keras.engine.sequential.Sequential at 0x7fdcf1457a90>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAN.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d08b6fd3-6e6d-4c55-afd3-c5a5b30292f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 28, 28)            143634    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 132951    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,585\n",
      "Trainable params: 143,634\n",
      "Non-trainable params: 132,951\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f44c7d-b4e5-4743-86de-b9dd21797708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               15150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 784)               118384    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 28, 28)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,634\n",
      "Trainable params: 143,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.layers[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0e161cf-ba6b-4988-807d-2c272b7009b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 150)               117750    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,951\n",
      "Trainable params: 0\n",
      "Non-trainable params: 132,951\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "096fcc5b-eeaa-4858-9617-28225190904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25b81293-0688-4731-9fc6-32c4bf41b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bb84771-663c-4f2d-8ab5-de98fd9cd8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = only_zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b5113bd-e003-4ed2-8a66-20bbfc11da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(my_data).shuffle(buffer_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a25d4b2-1635-4e36-b7bb-2e298813d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c890d7a9-92e2-4e8b-9dd9-2bf66a404bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training on batch 100 of 5923\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "generator, discriminator = GAN.layers\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    i = 0\n",
    "    \n",
    "    for X_batch in dataset:\n",
    "        i += 1\n",
    "        if i%100 == 0:\n",
    "            print(f\"Currently training on batch {i} of {len(my_data//batch_size)}\")\n",
    "        \n",
    "        # Discriminator Training\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        gen_images = generator(noise)\n",
    "        \n",
    "        X_fake_vs_real = tf.concat([gen_images, tf.dtypes.cast(X_batch, tf.float32)], axis = 0)\n",
    "        y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "        \n",
    "        discriminator.trainable = False\n",
    "        discriminator.train_on_batch(X_fake_vs_real, y1)\n",
    "        \n",
    "        # Generator Training\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        y2 = tf.constant([[1.]] * batch_size)\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        GAN.train_on_batch(noise, y2)\n",
    "        \n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a7a43-8f85-429b-b358-427d35184d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
