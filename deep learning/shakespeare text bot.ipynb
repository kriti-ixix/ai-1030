{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shakespeare text bot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFByzOut6Hjq",
        "outputId": "605d222a-9b6e-4f3b-a7dd-ef5a87841be6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries"
      ],
      "metadata": {
        "id": "gFsd_iDD9o2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OVsYcSb46giG",
        "outputId": "db6289c8-9f76-4119-9355-7d7b79d5d266"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "66qXAEcZ84nq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the Data"
      ],
      "metadata": {
        "id": "oa4Euh3c9wGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = \"/content/drive/MyDrive/shakespeare.txt\""
      ],
      "metadata": {
        "id": "P5iaSDgg9Erg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file).read()"
      ],
      "metadata": {
        "id": "XUJr37Vz9mlf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_39BJUB6-LRd",
        "outputId": "b0a99a4b-f9f9-4d58-f45a-28dd535c443c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding the Text Data"
      ],
      "metadata": {
        "id": "G_S-aTcO_kUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7oCOW9Y-Q70",
        "outputId": "f6aba9a1-7537-4505-a8df-a8c96c0f0a38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5445609"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44DFAL2dBI3W",
        "outputId": "774033e8-9c8e-413c-ed58-b0a5356f243a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))"
      ],
      "metadata": {
        "id": "mp17gNSj_w40"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXIhHogX_5Fd",
        "outputId": "1a331256-de2e-44b4-b002-9c71c2a90040"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(enumerate(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaq5jgQ8Byo7",
        "outputId": "c0c62fe3-2e10-4948-8ad1-55a672e9bb98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '\\n'),\n",
              " (1, ' '),\n",
              " (2, '!'),\n",
              " (3, '\"'),\n",
              " (4, '&'),\n",
              " (5, \"'\"),\n",
              " (6, '('),\n",
              " (7, ')'),\n",
              " (8, ','),\n",
              " (9, '-'),\n",
              " (10, '.'),\n",
              " (11, '0'),\n",
              " (12, '1'),\n",
              " (13, '2'),\n",
              " (14, '3'),\n",
              " (15, '4'),\n",
              " (16, '5'),\n",
              " (17, '6'),\n",
              " (18, '7'),\n",
              " (19, '8'),\n",
              " (20, '9'),\n",
              " (21, ':'),\n",
              " (22, ';'),\n",
              " (23, '<'),\n",
              " (24, '>'),\n",
              " (25, '?'),\n",
              " (26, 'A'),\n",
              " (27, 'B'),\n",
              " (28, 'C'),\n",
              " (29, 'D'),\n",
              " (30, 'E'),\n",
              " (31, 'F'),\n",
              " (32, 'G'),\n",
              " (33, 'H'),\n",
              " (34, 'I'),\n",
              " (35, 'J'),\n",
              " (36, 'K'),\n",
              " (37, 'L'),\n",
              " (38, 'M'),\n",
              " (39, 'N'),\n",
              " (40, 'O'),\n",
              " (41, 'P'),\n",
              " (42, 'Q'),\n",
              " (43, 'R'),\n",
              " (44, 'S'),\n",
              " (45, 'T'),\n",
              " (46, 'U'),\n",
              " (47, 'V'),\n",
              " (48, 'W'),\n",
              " (49, 'X'),\n",
              " (50, 'Y'),\n",
              " (51, 'Z'),\n",
              " (52, '['),\n",
              " (53, ']'),\n",
              " (54, '_'),\n",
              " (55, '`'),\n",
              " (56, 'a'),\n",
              " (57, 'b'),\n",
              " (58, 'c'),\n",
              " (59, 'd'),\n",
              " (60, 'e'),\n",
              " (61, 'f'),\n",
              " (62, 'g'),\n",
              " (63, 'h'),\n",
              " (64, 'i'),\n",
              " (65, 'j'),\n",
              " (66, 'k'),\n",
              " (67, 'l'),\n",
              " (68, 'm'),\n",
              " (69, 'n'),\n",
              " (70, 'o'),\n",
              " (71, 'p'),\n",
              " (72, 'q'),\n",
              " (73, 'r'),\n",
              " (74, 's'),\n",
              " (75, 't'),\n",
              " (76, 'u'),\n",
              " (77, 'v'),\n",
              " (78, 'w'),\n",
              " (79, 'x'),\n",
              " (80, 'y'),\n",
              " (81, 'z'),\n",
              " (82, '|'),\n",
              " (83, '}')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = {c : i for i, c in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "TGjhDUbsALVv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8NgiD1NByEF",
        "outputId": "2b77efa9-172b-4236-d92c-0c634542d173"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = np.array(vocab)\n",
        "index_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZsavvFmB_xa",
        "outputId": "85ffb011-bd79-48ef-f754-f528314bb2b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding the Text"
      ],
      "metadata": {
        "id": "uYEtoG2LE7ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_index[c] for c in text])"
      ],
      "metadata": {
        "id": "wWJGCWPUE1ma"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvD1ZtuUFKr2",
        "outputId": "9a2725d3-2de5-4e1f-e936-bbd8df280b76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfcT9mZiGtkh",
        "outputId": "57db9ff4-4c08-45aa-8506-87c913d9f0f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75\n",
            "  1 56 74  1 75 63 60  1 73 64 71 60 73  1 74 63 70 76 67 59  1 57 80  1\n",
            " 75 64 68 60  1 59 60 58 60 56 74 60  8  0  1  1 33 64 74  1 75 60 69 59\n",
            " 60 73  1 63 60 64 73  1 68 64 62 63 75  1 57 60 56 73  1 63 64 74  1 68\n",
            " 60 68 70 73 80 21  0  1  1 27 76 75  1 75 63 70 76  1 58 70 69 75 73 56\n",
            " 58 75 60 59  1 75 70  1 75 63 64 69 60  1 70 78 69  1 57 73 64 62 63 75\n",
            "  1 60 80 60 74  8  0  1  1 31 60 60 59  5 74 75  1 75 63 80  1 67 64 62\n",
            " 63 75  5 74  1 61 67 56 68 60  1 78 64 75 63  1 74 60 67 61  9 74 76 57\n",
            " 74 75 56 69 75 64 56 67  1 61 76 60 67  8  0  1  1 38 56 66 64 69 62  1\n",
            " 56  1 61 56 68 64 69 60  1 78 63 60 73 60  1 56 57 76 69 59 56 69 58 60\n",
            "  1 67 64 60 74  8  0  1  1 45 63 80  1 74 60 67 61  1 75 63 80  1 61 70\n",
            " 60  8  1 75 70  1 75 63 80  1 74 78 60 60 75  1 74 60 67 61  1 75 70 70\n",
            "  1 58 73 76 60 67 21  0  1  1 45 63 70 76  1 75 63 56 75  1 56 73 75  1\n",
            " 69 70 78  1 75 63 60  1 78 70 73 67 59  5 74  1 61 73 60 74 63  1 70 73\n",
            " 69 56 68 60 69 75  8  0  1  1 26 69 59  1 70 69 67 80  1 63 60 73 56 67\n",
            " 59  1 75 70  1 75 63 60  1 62 56 76 59 80  1 74 71 73 64 69 62  8  0  1\n",
            "  1 48 64 75 63 64 69  1 75 63 64 69 60  1 70 78 69  1 57 76]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Batches"
      ],
      "metadata": {
        "id": "Q3J9YqheCzcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "id": "eZL_XZN5GxFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c477d1-0957-4804-d6af-3780c3bc5726"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(\"From fairest creatures we desire increase,\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFb7ibrsDSAW",
        "outputId": "e869a284-c71a-4ab5-fc9f-114c3e3b7a07"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len('''From fairest creatures we desire increase,\n",
        "That thereby beauty's rose might never die,\n",
        "But as the riper should by time decease,''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuiJo01ODb7u",
        "outputId": "8df5a2ba-e202-43ae-e40a-4d29f30d6c20"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 120"
      ],
      "metadata": {
        "id": "LA-BtyqcDonP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text) // (seq_len + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKag-2S6D5Tn",
        "outputId": "f7d8fa96-76c6-4bba-c786-3266bad8812a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "metadata": {
        "id": "Hq2g4TmVD-f0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in char_dataset.take(500):\n",
        "  print(index_to_char[i.numpy()], end = \"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADgKFSIWEZfJ",
        "outputId": "fba453c9-5d6c-4e9c-c938-42e74ef4637a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_len + 1, drop_remainder = True)"
      ],
      "metadata": {
        "id": "xFPUlKcuEotL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvUA0nMqGixT",
        "outputId": "6f0437c8-76b7-4baa-a950-2427f8be5d12"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=TensorSpec(shape=(121,), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_targets(seq):\n",
        "  input_txt = seq[:-1] # Excluding the last character\n",
        "  target_txt = seq[1:] # Excluding the first character\n",
        "  return input_txt, target_txt"
      ],
      "metadata": {
        "id": "2Q2Gynh7GkQr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(create_targets)"
      ],
      "metadata": {
        "id": "g4GE3izMHHWa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWsB09f-IwGA",
        "outputId": "72e2997d-3057-48a5-d75f-66eb4535c204"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(120,), dtype=tf.int64, name=None), TensorSpec(shape=(120,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input, target in dataset.take(1):\n",
        "  print(input.numpy(), end = \"\\n\")\n",
        "  print()\n",
        "  print(target.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsObgxz_HP0x",
        "outputId": "3acd90c6-c5fa-4bce-cae6-0d54594ec724"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "86_C3UA0Hsqk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "vCMnVrveKsA6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc3QdWsDK-s_",
        "outputId": "6f722b51-3860-4081-db6d-e18a0bd02ab9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the Model"
      ],
      "metadata": {
        "id": "wVVE8p3ML8o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 64\n",
        "rnn_neurons = 1026"
      ],
      "metadata": {
        "id": "myhBWxHHLDbs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4reB15v0NcSK",
        "outputId": "74204d6d-a5bd-4ab6-f538-0bd13a0ae1a7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, GRU\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "_6Ck0Tf3MFK3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_cat_loss(y_true, y_pred):\n",
        "  scce = SparseCategoricalCrossentropy(from_logits=True)\n",
        "  return scce(y_true, y_pred)"
      ],
      "metadata": {
        "id": "J6ep4FJUNrn9"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocab_size, embedding_dim, rnn_neurons, batch_size):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, embedding_dim, batch_input_shape=(batch_size, None)))\n",
        "  model.add(GRU(rnn_neurons, return_sequences=True, stateful=True))\n",
        "  model.add(Dense(vocab_size))\n",
        "  model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
        "  return model"
      ],
      "metadata": {
        "id": "3HfzJXJ7OKKd"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size, embedding_dim, rnn_neurons, batch_size)"
      ],
      "metadata": {
        "id": "HU5UOh4OQHVl"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px-QFZryQQGv",
        "outputId": "26398f08-ba86-441e-bc11-198acc6ac0c8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_predictions = model(input_example_batch)\n",
        "  print(example_predictions.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WCTkdmYQTQM",
        "outputId": "c4aec4fc-8707-48a5-9034-56937e6ea565"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 120, 84)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "128 -> batch size\n",
        "\n",
        "120 -> sequence length\n",
        "\n",
        "84 -> vocabulary size"
      ],
      "metadata": {
        "id": "k_Kq3fe1QzIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_values = tf.random.categorical(example_predictions[0], num_samples=1)\n",
        "example_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXnjN086Quqa",
        "outputId": "4c105707-f820-40e9-cb39-3b5128223483"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[74],\n",
              "       [62],\n",
              "       [59],\n",
              "       [63],\n",
              "       [40],\n",
              "       [75],\n",
              "       [56],\n",
              "       [62],\n",
              "       [56],\n",
              "       [30],\n",
              "       [28],\n",
              "       [78],\n",
              "       [68],\n",
              "       [41],\n",
              "       [15],\n",
              "       [25],\n",
              "       [80],\n",
              "       [80],\n",
              "       [54],\n",
              "       [21],\n",
              "       [43],\n",
              "       [23],\n",
              "       [38],\n",
              "       [24],\n",
              "       [29],\n",
              "       [46],\n",
              "       [20],\n",
              "       [35],\n",
              "       [80],\n",
              "       [78],\n",
              "       [56],\n",
              "       [27],\n",
              "       [27],\n",
              "       [12],\n",
              "       [76],\n",
              "       [26],\n",
              "       [81],\n",
              "       [25],\n",
              "       [75],\n",
              "       [32],\n",
              "       [40],\n",
              "       [18],\n",
              "       [20],\n",
              "       [45],\n",
              "       [38],\n",
              "       [26],\n",
              "       [39],\n",
              "       [31],\n",
              "       [19],\n",
              "       [80],\n",
              "       [83],\n",
              "       [36],\n",
              "       [43],\n",
              "       [65],\n",
              "       [36],\n",
              "       [75],\n",
              "       [67],\n",
              "       [79],\n",
              "       [77],\n",
              "       [60],\n",
              "       [27],\n",
              "       [32],\n",
              "       [24],\n",
              "       [ 4],\n",
              "       [54],\n",
              "       [44],\n",
              "       [44],\n",
              "       [28],\n",
              "       [54],\n",
              "       [74],\n",
              "       [ 8],\n",
              "       [53],\n",
              "       [56],\n",
              "       [ 4],\n",
              "       [29],\n",
              "       [50],\n",
              "       [28],\n",
              "       [82],\n",
              "       [34],\n",
              "       [66],\n",
              "       [73],\n",
              "       [31],\n",
              "       [12],\n",
              "       [23],\n",
              "       [82],\n",
              "       [46],\n",
              "       [ 3],\n",
              "       [30],\n",
              "       [46],\n",
              "       [49],\n",
              "       [46],\n",
              "       [56],\n",
              "       [35],\n",
              "       [72],\n",
              "       [37],\n",
              "       [ 5],\n",
              "       [52],\n",
              "       [14],\n",
              "       [55],\n",
              "       [11],\n",
              "       [16],\n",
              "       [67],\n",
              "       [81],\n",
              "       [70],\n",
              "       [38],\n",
              "       [ 0],\n",
              "       [13],\n",
              "       [76],\n",
              "       [ 1],\n",
              "       [22],\n",
              "       [69],\n",
              "       [75],\n",
              "       [33],\n",
              "       [ 6],\n",
              "       [24],\n",
              "       [62],\n",
              "       [26],\n",
              "       [70],\n",
              "       [31],\n",
              "       [69]])>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_values = tf.squeeze(example_values, axis = 1).numpy()"
      ],
      "metadata": {
        "id": "V0ob5XxvRJJB"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vkbWgDjRlP-",
        "outputId": "c428b24a-41d1-4f9b-e7ed-1168031acecf"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([74, 62, 59, 63, 40, 75, 56, 62, 56, 30, 28, 78, 68, 41, 15, 25, 80,\n",
              "       80, 54, 21, 43, 23, 38, 24, 29, 46, 20, 35, 80, 78, 56, 27, 27, 12,\n",
              "       76, 26, 81, 25, 75, 32, 40, 18, 20, 45, 38, 26, 39, 31, 19, 80, 83,\n",
              "       36, 43, 65, 36, 75, 67, 79, 77, 60, 27, 32, 24,  4, 54, 44, 44, 28,\n",
              "       54, 74,  8, 53, 56,  4, 29, 50, 28, 82, 34, 66, 73, 31, 12, 23, 82,\n",
              "       46,  3, 30, 46, 49, 46, 56, 35, 72, 37,  5, 52, 14, 55, 11, 16, 67,\n",
              "       81, 70, 38,  0, 13, 76,  1, 22, 69, 75, 33,  6, 24, 62, 26, 70, 31,\n",
              "       69])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input example batch \\n\\n\")\n",
        "print(''.join(index_to_char[input_example_batch[0]]))\n",
        "\n",
        "print(\"\\n\\nTarget example batch \\n\\n\")\n",
        "print(''.join(index_to_char[sample_values]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d3G5mB-RpR_",
        "outputId": "8a7186ec-9097-4630-bb61-a40a85aab046"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input example batch \n",
            "\n",
            "\n",
            "o those thorns that in her bosom lodge\n",
            "    To prick and sting her. Fare thee well at once.\n",
            "    The glowworm shows the ma\n",
            "\n",
            "\n",
            "Target example batch \n",
            "\n",
            "\n",
            "sgdhOtagaECwmP4?yy_:R<M>DU9JywaBB1uAz?tGO79TMANF8y}KRjKtlxveBG>&_SSC_s,]a&DYC|IkrF1<|U\"EUXUaJqL'[3`05lzoM\n",
            "2u ;ntH(>gAoFn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "model.fit(dataset, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_q_FSqfR1nv",
        "outputId": "10951a98-8a0f-47c3-8291-f5d613459010"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "351/351 [==============================] - 46s 122ms/step - loss: 2.6326\n",
            "Epoch 2/30\n",
            "351/351 [==============================] - 45s 125ms/step - loss: 1.8042\n",
            "Epoch 3/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.5142\n",
            "Epoch 4/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.3774\n",
            "Epoch 5/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.3054\n",
            "Epoch 6/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.2600\n",
            "Epoch 7/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 1.2270\n",
            "Epoch 8/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.2015\n",
            "Epoch 9/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.1799\n",
            "Epoch 10/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 1.1615\n",
            "Epoch 11/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.1452\n",
            "Epoch 12/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.1301\n",
            "Epoch 13/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 1.1158\n",
            "Epoch 14/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 1.1029\n",
            "Epoch 15/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 1.0908\n",
            "Epoch 16/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.0787\n",
            "Epoch 17/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 1.0671\n",
            "Epoch 18/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.0562\n",
            "Epoch 19/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.0459\n",
            "Epoch 20/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.0365\n",
            "Epoch 21/30\n",
            "351/351 [==============================] - 46s 128ms/step - loss: 1.0266\n",
            "Epoch 22/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 1.0176\n",
            "Epoch 23/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.0098\n",
            "Epoch 24/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 1.0019\n",
            "Epoch 25/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 0.9955\n",
            "Epoch 26/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 0.9890\n",
            "Epoch 27/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 0.9834\n",
            "Epoch 28/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 0.9778\n",
            "Epoch 29/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 0.9734\n",
            "Epoch 30/30\n",
            "351/351 [==============================] - 46s 127ms/step - loss: 0.9690\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f78634f10>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Shakespeare Model.h5')"
      ],
      "metadata": {
        "id": "MGRqyYuDSYU9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"Shakespeare Model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_OI5YtB5caFX",
        "outputId": "b9d3b9e9-df8b-44cb-e5bc-39d1846ba0e9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c1d9df15-1c23-4a95-83c4-172b03b0ae93\", \"Shakespeare Model.h5\", 41468624)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = create_model(vocab_size, embedding_dim, rnn_neurons, 1)\n",
        "model.load_weights(\"Shakespeare Model.h5\")\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "n__ClFU_cpIJ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW3I5nBOdiur",
        "outputId": "0ec1ce39-cd25-484b-d961-79e3f425c554"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (1, None, 64)             5376      \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (1, None, 84)             86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hrk7Alt0dpFa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
